\chapter{Анатомия синхронизации: Mutex vs Atomic и цена ожидания}

Многопоточное программирование в C++ строится на примитивах синхронизации, предоставляемых стандартной библиотекой. В основе всех \textit{lock-free} и \textit{wait-free} алгоритмов лежит фундаментальный строительный блок — \texttt{std::atomic}.

\section{Атомарные переменные: базовый API}

Атомарная переменная (\texttt{std::atomic<T>}) гарантирует отсутствие гонок данных (\textit{data race}) при одновременном доступе из нескольких потоков. Это достигается за счет использования специальных инструкций процессора (например, \texttt{LOCK XADD} на x86) или барьеров памяти.

Ключевая особенность атомиков в том, что операции над ними (загрузка, сохранение, инкремент) неделимы. Невозможна ситуация, когда один поток прочитал "половину" записанного значения или когда два потока одновременно инкрементировали переменную, но результат увеличился только на 1.

\subsection{Базовые операции}

\begin{cppcode}[]
#include <atomic>

std::atomic<int> counter{0};

void worker() {
    // 1. Атомарная запись (Store)
    counter.store(10); 
    
    // 2. Атомарное чтение (Load)
    int val = counter.load();
    
    // 3. Атомарная модификация (Read-Modify-Write)
    // Возвращает ПРЕДЫДУЩЕЕ значение
    int old_val = counter.fetch_add(1); 
    
    // Эквивалентно fetch_add(1), но возвращает
    // результат в зависимости от перегрузки (post/pre)
    counter++; 
}
\end{cppcode}

API \texttt{std::atomic} различается для разных типов данных:
\begin{itemize}
    \item \textbf{Целочисленные типы:} Поддерживают арифметику \texttt{fetch\_add}, \texttt{fetch\_sub}, \texttt{fetch\_and}, \texttt{fetch\_or}, \texttt{fetch\_xor}.
    \item \textbf{Указатели:} Поддерживают адресную арифметику (например, \texttt{fetch\_add} сдвигает указатель на размер типа).
    \item \textbf{Пользовательские структуры:} Поддерживают только \texttt{load}, \texttt{store} и \texttt{compare\_exchange} (CAS).
\end{itemize}

\section{Сравнительный анализ: Atomic vs Mutex}

Существует распространенное заблуждение, что атомарные операции всегда быстрее, чем использование \texttt{std::mutex}. Это утверждение верно только для определенных сценариев и часто ложно при высокой конкуренции (\textit{high contention}).

\subsection{Бенчмарк: Инкремент счетчика}

Рассмотрим классический бенчмарк: $N$ потоков инкрементируют одну общую переменную.

\textbf{Вариант 1: Mutex}
\begin{cppcode}
std::mutex mtx;
int shared_data = 0;

void mutex_inc() {
    std::lock_guard<std::mutex> lock(mtx);
    shared_data++;
}
\end{cppcode}

\textbf{Вариант 2: Atomic}
\begin{cppcode}
std::atomic<int> shared_data{0};

void atomic_inc() {
    shared_data.fetch_add(1, std::memory_order_relaxed);
}
\end{cppcode}

При малом количестве потоков (1-4) атомарная версия работает быстрее, так как отсутствует накладной расход на захват блокировки. Однако, по мере роста числа потоков (например, до 16 и выше на 8-ядерном процессоре), производительность атомиков деградирует.

\textbf{Физика процесса:}
Атомарный инкремент требует эксклюзивного владения кэш-линией (\textit{cache coherency protocol}, например, MESI). Когда множество ядер пытаются записать в одну и ту же переменную, кэш-линия начинает "метаться" между ядрами (cache ping-pong). Шина процессора насыщается трафиком синхронизации кэшей.

В случае \texttt{std::mutex}, потоки, не сумевшие захватить блокировку, уходят в режим ожидания (sleep) на уровне ядра ОС. Они перестают конкурировать за шину памяти, позволяя владельцу мьютекса быстро выполнить работу.

\begin{summary}
\texttt{std::mutex} может оказаться эффективнее \texttt{std::atomic} при высокой конкуренции, так как он сериализует доступ и убирает паразитную нагрузку на шину памяти от ожидающих потоков.
\end{summary}

\section{Анатомия ожидания: Spinlock, Futex и Throttling}

Понимание того, как реализован \texttt{std::mutex} "под капотом", критически важно для выбора инструмента синхронизации.

\subsection{Spinlock (Спинлок)}

Простейшая реализация блокировки на атомиках — это Spinlock. Поток крутится в цикле, постоянно проверяя флаг, пока не получит доступ.

\begin{definition}{Spinlock}
Механизм синхронизации, при котором ожидающий поток не приостанавливает свое выполнение, а находится в цикле активного ожидания (\textit{busy wait}), потребляя такты процессора.
\end{definition}

\begin{cppcode}
class Spinlock {
    std::atomic_flag flag = ATOMIC_FLAG_INIT;

public:
    void lock() {
        // test_and_set возвращает true, если флаг УЖЕ был установлен.
        // Если вернул false — мы успешно установили флаг (захватили лок).
        // memory_order_acquire — для корректной синхронизации.
        while (flag.test_and_set(std::memory_order_acquire)) {
            // Busy wait: поток сжигает CPU впустую
            // На x86 здесь часто ставят инструкцию _mm_pause()
        }
    }

    void unlock() {
        flag.clear(std::memory_order_release);
    }
};
\end{cppcode}

\textbf{Проблема Spinlock в Userspace:}
Использование спинлоков в прикладном коде (userspace) — опасный анти-паттерн. 
\begin{enumerate}
    \item \textbf{CPU Burning:} Поток занимает ядро на 100\%, не выполняя полезной работы. Это тратит энергию и греет процессор.
    \item \textbf{Priority Inversion:} Если высокоприоритетный поток ждет спинлок, захваченный низкоприоритетным потоком, а планировщик не дает времени владельцу, система может зависнуть.
\end{enumerate}

\subsection{Проблема троттлинга (Throttling)}

Особая опасность спинлоков возникает в облачных средах (Docker, Kubernetes) с лимитами по CPU.

Представьте ситуацию:
\begin{enumerate}
    \item Поток А захватывает спинлок.
    \item Планировщик ОС (или гипервизор) прерывает выполнение потока А, так как его квант времени (timeslice) истек.
    \item Поток Б пытается захватить тот же спинлок. Он начинает крутиться в \texttt{while}, сжигая свой квант времени.
    \item Поток Б не может продвинуться, так как Поток А "спит" и не может освободить лок.
\end{enumerate}

Если квота CPU исчерпана, поток А может быть "заморожен" на десятки миллисекунд (throttling latency). Все это время остальные потоки, ожидающие спинлок, просто сжигают процессорное время впустую.

\subsection{Реализация Mutex через Futex}

Современный \texttt{std::mutex} (например, в Linux через glibc/pthreads) использует гибридную схему, основанную на системном вызове \textbf{futex} (Fast Userspace Mutex).

Алгоритм работы \texttt{std::mutex::lock()}:
\begin{enumerate}
    \item \textbf{Fast Path (Userspace):} Поток пытается атомарно (CAS) изменить состояние мьютекса с "свободен" на "занят". Если удается — блокировка захвачена без системного вызова. Это очень быстро (десятки наносекунд).
    \item \textbf{Slow Path (Kernel Space):} Если мьютекс занят, поток делает системный вызов \texttt{futex\_wait}. Ядро ОС переводит поток в состояние \texttt{BLOCKED} и убирает его из очереди планирования. Поток перестает потреблять CPU.
\end{enumerate}

Когда владелец вызывает \texttt{unlock()}, он сначала освобождает флаг, а затем (если есть ожидающие) делает \texttt{futex\_wake}, чтобы ядро разбудило один из спящих потоков.

\begin{important}
\texttt{std::mutex} эффективен, потому что ожидание переносится в ядро (\textit{kernel space}). Spinlock же оставляет ожидание в пространстве пользователя, сжигая ресурсы.
\end{important}

\section{Аппаратные ограничения и std::atomic<T>}

Не любой тип \texttt{T} может быть обработан атомарно на аппаратном уровне. Процессоры обычно гарантируют атомарность только для типов, помещающихся в машинное слово (64 бита) или двойное слово (128 бит, инструкция \texttt{CMPXCHG16B} на x64).

\subsection{is\_always\_lock\_free}

Стандарт C++ предоставляет механизм проверки, является ли атомик "настоящим" (lock-free) или эмулируется библиотекой.

\begin{cppcode}
struct LargeData {
    char buffer[400]; // Слишком большой для регистра CPU
};

std::atomic<LargeData> data;

// Вернет false, так как процессор не умеет атомарно писать 400 байт
bool is_fast = std::atomic<LargeData>::is_always_lock_free; 
\end{cppcode}

Если \texttt{is\_always\_lock\_free} ложно, компилятор реализует \texttt{std::atomic} через скрытый глобальный мьютекс (хеш-таблица мьютексов). В этом случае использование \texttt{std::atomic} теряет смысл с точки зрения производительности и свойства lock-free.

\begin{note}
Перед использованием \texttt{std::atomic} со структурами всегда проверяйте \texttt{is\_always\_lock\_free} через \texttt{static\_assert}.
\end{note}

\section{Эволюция ожидания в C++20}

До C++20 у разработчиков не было стандартного способа реализовать эффективное ожидание на атомарной переменной без спинлоков или использования сторонних мьютексов/condition variables.

В C++20 добавлены методы \texttt{wait}, \texttt{notify\_one} и \texttt{notify\_all} непосредственно в \texttt{std::atomic}. Это фактически предоставляет интерфейс футексов на уровне языка.

\begin{cppcode}[]
#include <atomic>
#include <thread>

std::atomic<int> signal_flag{0};

void consumer() {
    // Эффективное ожидание:
    // Блокирует поток, пока signal_flag == 0.
    // Не потребляет CPU в цикле!
    int value = 0;
    while ((value = signal_flag.load()) == 0) {
        signal_flag.wait(0); 
    }
    // ... работаем ...
}

void producer() {
    signal_flag.store(1);
    signal_flag.notify_one(); // Будим ожидающий поток
}
\end{cppcode}

Метод \texttt{wait(old\_val)} работает следующим образом:
\begin{enumerate}
    \item Атомарно сравнивает текущее значение атомика с \texttt{old\_val}.
    \item Если значения не равны — немедленно возвращает управление (значение уже изменилось).
    \item Если равны — поток усыпляется (как на мьютексе/футексе) до вызова \texttt{notify}.
\end{enumerate}

Это позволяет строить эффективные механизмы синхронизации, сочетающие скорость атомиков (fast path) и энергоэффективность блокировок (slow path).

